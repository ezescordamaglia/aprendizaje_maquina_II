{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje de máquina II\n",
    "### Carrera de especialización en inteligencia artificial  \n",
    "\n",
    "#### **VERSIONADO DE MODELOS USANDO MLFLOW**\n",
    "\n",
    "Este ejemplo pertenece a la [documentación](https://github.com/mlflow/mlflow/tree/master/examples/sklearn_elasticnet_wine) de MLflow, con algunas modificaciones para trackear nuestros modelos utilizando sqlite.  \n",
    "\n",
    "Para poder reproducir los resultados vistos en clase seguir los siguientes pasos:\n",
    "\n",
    "* Si bien no es obligatorio, es **altamente** recomendable crearse un nuevo ambiente para administrar las dependencias y asegurar la correcta ejecución.  \n",
    "Si estamos utilizando conda podemos crear un nuevo entorno con el comando:\n",
    "`conda create -n mlflow python=3.8`  \n",
    "Al ejecutar ese comando se nos creará un ambiente llamado \"mlflow\" (cambiar el nombre si se lo desea) con python versión 3.8.  \n",
    "\n",
    "Podemos activar nuestro nuevo ambiente ejecutando:  \n",
    "`conda activate mlflow`  \n",
    "_(En caso de haber elegido otro nombre para el ambiente, reemplazar \"mlflow\" por el nombre que hayamos elegido)_\n",
    "\n",
    "\n",
    "Para completar la instalación del ambiente debemos instalar las siguientes dependencias:  \n",
    "\n",
    "  - scikit-learn==1.2.0\n",
    "  - mlflow\n",
    "  - pandas\n",
    "\n",
    "Para esto podemos utilizar `pip install nombre_de_la_biblioteca` desde la consola de conda.  \n",
    "\n",
    "* Luego de configurar nuestro ambiente debemos abrir la command prompt de conda y movernos hacia el directorio en donde tengamos guardado este notebook. Como recomendación, guardarlo en una carpeta exclusiva, ya que se nos irán generando algunos archivos complementarios para poder realizar el tutorial.\n",
    "\n",
    "En caso de que no hayan navegado por una consola de comandos, [acá](http://www.falconmasters.com/offtopic/como-utilizar-consola-de-windows/#:~:text=Para%20acceder%20a%20ella%20lo,en%20la%20consola%20de%20windows.) hay un breve tutorial con los comandos más útiles.\n",
    "\n",
    "\n",
    "* Una vez dentro de la carpeta donde almacenamos este notebook, debemos indicarle a mlflow que vamos a utilizar SQLite como backend para almacenar nuestros modelos registrados. Para ello, desde la command prompt de conda debemos ejecutar:  \n",
    "`mlflow server --backend-store-uri sqlite:///mydb.sqlite`  \n",
    "Luego de ejecutar ese comando veremos que en la carpeta se crearán una carpeta donde se almacenarám los artefactos de mlflow y una base de datos para el model registry.  \n",
    "También debemos ver en la consola el siguiente mensaje:\n",
    "`INFO:waitress:Serving on http://127.0.0.1:5000`\n",
    "\n",
    "* Esa dirección IP corresponde a nuestro localhost y el número 5000 al número de puerto donde podremos consultar la UI de mlflow.  \n",
    "Si copiamos y pegamos esa dirección http en algún buscador web, podremos acceder a la UI.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1683674403505, experiment_id='1', last_update_time=1683674403505, lifecycle_stage='active', name='Wine_prediction_experiment', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "mlflow.set_experiment(\"Wine_prediction_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for the customModel\n",
    "import pickle\n",
    "import cloudpickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "\n",
    "class CustomModelPredictor(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"\n",
    "    This Class define a custom model predictor to calculate something.\n",
    "\n",
    "    It derives from the mlflow PythonModel base Class and has three\n",
    "    main methods to work, fit, predict and load_context.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_params: dict):\n",
    "\n",
    "        self.preprocessor = StandardScaler()\n",
    "        self.model = RandomForestRegressor(**model_params)\n",
    "\n",
    "    def load_context(self, context) -> None:\n",
    "        \"\"\"\n",
    "        This method will not be explicitly used in this module, but it is\n",
    "        necessary for mlflow to understand how to load what has been\n",
    "        trained further on, by loading the needed artifacts.\n",
    "\n",
    "        :param context: A :class:`~PythonModelContext` instance containing artifacts that the model\n",
    "                        can use to perform inference.\n",
    "        \"\"\"\n",
    "\n",
    "        with open(context.artifacts[\"preprocessor\"], \"rb\") as f:\n",
    "            self.preprocessor = pickle.load(f)\n",
    "        with open(context.artifacts[\"estimator\"], \"rb\") as f:\n",
    "            self.model = pickle.load(f)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def fit(self, X_train = np.ndarray, y_train = np.ndarray, X_val = None, y_val = None) -> None:\n",
    "        \"\"\"\n",
    "        This method will take a pandas DataFrame, fit the model, save that as a\n",
    "        serialized pickle object and return the signature of the model\n",
    "\n",
    "        :param X_train: the training input samples.\n",
    "        :type X_train: pd.DataFrame\n",
    "\n",
    "        :param y_train: the training output target.\n",
    "        :type y_train: pd.DataFrame\n",
    "\n",
    "        :param X_val: the validation input samples.\n",
    "        :type X_val: pd.DataFrame\n",
    "\n",
    "        :param y_val: the validation output target.\n",
    "        :type y_val: pd.DataFrame\n",
    "\n",
    "        :return: signature of the model\n",
    "        :rtype: ModelSignature\n",
    "        \"\"\"\n",
    "\n",
    "        # TRAINING THE PIPELINE\n",
    "\n",
    "        self.preprocessor.fit(X=X_train, y=y_train)\n",
    "        X_train_transformed = self.preprocessor.transform(X=X_train)\n",
    "        self.model.fit(X_train_transformed, y_train)\n",
    "\n",
    "        # MODEL EVALUATION AND LOGGING METRICS\n",
    "\n",
    "        # Train metrics\n",
    "        y_train_pred = self.model.predict(X_train_transformed)\n",
    "        rmse, mae, r2 = eval_metrics(y_train_pred, y_train)\n",
    "        mlflow.log_metric(\"train_rmse\", rmse)\n",
    "        mlflow.log_metric(\"train_r2\", r2)\n",
    "        mlflow.log_metric(\"train_mae\", mae)\n",
    "\n",
    "        if X_val is not None and y_val is not None:\n",
    "            # Validation metrics\n",
    "            X_val_transformed = self.preprocessor.transform(X_val)\n",
    "            y_val_pred = self.model.predict(X_val_transformed)\n",
    "            rmse, mae, r2 = eval_metrics(y_val_pred, y_val)\n",
    "            mlflow.log_metric(\"val_rmse\", rmse)\n",
    "            mlflow.log_metric(\"val_r2\", r2)\n",
    "            mlflow.log_metric(\"val_mae\", mae)\n",
    "\n",
    "        # Dumping fitted objects\n",
    "        with open(\"./fitted_model.pkl\", \"wb\") as f:\n",
    "            cloudpickle.dump(self.model, f)\n",
    "        with open(\"./fitted_preprocessor.pkl\", \"wb\") as f:\n",
    "            cloudpickle.dump(self.preprocessor, f)\n",
    "\n",
    "        # Inferring signature to return\n",
    "        signature = infer_signature(X_train, y_train)\n",
    "\n",
    "        return signature\n",
    "\n",
    "    def predict(self,context, X: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        This method will evaluate a proper input with the loaded context\n",
    "        and return the predicted output.\n",
    "\n",
    "        :param X: the inputted DataFrame with the features of the model\n",
    "        :type X: pd.DataFrame\n",
    "\n",
    "        :return: probability predictions of the occurrence of the event given by the model\n",
    "        :rtype: np.ndarray\n",
    "        \"\"\"\n",
    "        X_transformed = self.preprocessor.transform(X)\n",
    "        predictions = self.model.predict(X_transformed)\n",
    "        \n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "\n",
    "    # Read the wine-quality csv file from the URL\n",
    "    csv_url = (\n",
    "        \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-red.csv\"\n",
    "    )\n",
    "    try:\n",
    "        data = pd.read_csv(csv_url, sep=\";\")\n",
    "    except Exception as e:\n",
    "        logger.exception(\n",
    "            \"Unable to download training & test CSV, check your internet connection. Error: %s\", e\n",
    "        )\n",
    "\n",
    "    # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "    train, test = train_test_split(data, test_size=0.25, random_state=20, shuffle=True)\n",
    "    train, val = train_test_split(train, test_size=0.25, random_state=20, shuffle=True)\n",
    "\n",
    "    # The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "    train_x = train.drop([\"quality\"], axis=1)\n",
    "    test_x = test.drop([\"quality\"], axis=1)\n",
    "    val_x = val.drop([\"quality\"], axis=1)\n",
    "    train_y = train[[\"quality\"]]\n",
    "    test_y = test[[\"quality\"]]\n",
    "    val_y = val[[\"quality\"]]\n",
    "\n",
    "    model_params = {\n",
    "                    'max_depth' : 10,\n",
    "                    'n_estimators' : 27\n",
    "                    }\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        CMP = CustomModelPredictor(model_params = model_params)\n",
    "        signature = CMP.fit(train_x, train_y, val_x, val_y)\n",
    "\n",
    "        mlflow.log_param(\"model_params\", model_params)\n",
    "\n",
    "        # Log the model\n",
    "        # conda_env = \"conda.yaml\"\n",
    "        conda_env = {\n",
    "            \"name\": \"mlflow-env\",\n",
    "            \"channels\": [\"defaults\", \"anaconda\", \"conda-forge\"],\n",
    "            \"dependencies\": [\n",
    "                \"python==3.8.16\",\n",
    "                \"cloudpickle==1.6.0\",\n",
    "                \"scikit-learn==0.22.1\",\n",
    "                \"ortools==9.4.1874\",\n",
    "            ],\n",
    "        }\n",
    "        artifacts = {\n",
    "            \"preprocessor\": \"./fitted_preprocessor.pkl\",\n",
    "            \"estimator\": \"./fitted_model.pkl\",\n",
    "        }\n",
    "\n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"model\",\n",
    "            artifacts=artifacts,\n",
    "            python_model=CMP,\n",
    "            conda_env=conda_env,\n",
    "            signature=signature,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/17 00:37:41 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - mlflow (current: 2.3.2, required: mlflow==2.3)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    }
   ],
   "source": [
    "model_production = mlflow.pyfunc.load_model('models:/ElasticnetWineModel/production')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom model test metrics\n",
      "  RMSE: 0.6078979712332924\n",
      "  MAE: 0.453315437430186\n",
      "  R2: 0.3770858210818864\n"
     ]
    }
   ],
   "source": [
    "predicted_qualities = model_production.predict(test_x)\n",
    "\n",
    "(rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "print(\"Custom model test metrics\")\n",
    "print(\"  RMSE: %s\" % rmse)\n",
    "print(\"  MAE: %s\" % mae)\n",
    "print(\"  R2: %s\" % r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
